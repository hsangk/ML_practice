{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-03T21:43:18.993052Z",
     "end_time": "2023-10-03T21:43:19.020757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, load_digits, load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 로드\n",
    "iris = load_wine()\n",
    "X = iris.data[:,:] # 꽃잎의 길이, 너비\n",
    "print(X)\n",
    "Y = iris.target\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=2021,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\lifelog\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\Anaconda3\\envs\\lifelog\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression  :  0.9629629629629629\n",
      "RandomForestClassifier  :  0.9814814814814815\n",
      "SVC  :  0.7407407407407407\n",
      "VotingClassifier  :  0.9814814814814815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\lifelog\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 약한 학습기 구축\n",
    "log_model = LogisticRegression()\n",
    "rnd_model = RandomForestClassifier()\n",
    "svm_model = SVC()\n",
    "\n",
    "# 앙상블 모델 구축\n",
    "# 만약에 모든 모델이 predict_proba() 메서드가 있으면, 예측의 평균을 내어 soft voting(간접 투표)도 할수 있다.\n",
    "# 간접 투표 방식은 확률이 높은 투표에 비중을 두기 때문에 성능이 더 높다. (voting='soft' 사용)\n",
    "# svc는 기본적으로 predict_proba를 제공하지 않아, probability = True 지정 해야 사용 가능\n",
    "# 대신 svc에서 probability = True를 지정하면 교차 검증을 사용해서 확률을 추정하기 때문에 훈련 속도 느려짐\n",
    "# 대신 성능을 올라감\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('lr',log_model),('rf',rnd_model),('svc',svm_model)], # 3개의 약한 학습기\n",
    "    voting='hard' # 직접 투표(hard voting)\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "voting_model.fit(x_train,y_train)\n",
    "\n",
    "# 모델 비교\n",
    "for model in (log_model,rnd_model,svm_model,voting_model):\n",
    "  model.fit(x_train,y_train)\n",
    "  y_pred = model.predict(x_test)\n",
    "  print(model.__class__.__name__,\" : \",accuracy_score(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T21:43:20.139748Z",
     "end_time": "2023-10-03T21:43:20.611138Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier  :  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 모델 구축\n",
    "# BaggingClassifier에서 사용한 분류기가 클래스 확률추정(predict_proba)이 가능하면 자동으로 간접 투표 사용\n",
    "bag_model = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), # 약한 학습기(결정 트리)\n",
    "    n_estimators=500, # 약한 학습기(결정 트리) 500개 생성\n",
    "    max_samples=0.05, # 0.0~1.0 사이 실수 선택(실수 x 샘플 수) 혹은 샘플수 지정\n",
    "    bootstrap=True, # True : 배깅, False : 페이스팅\n",
    "    n_jobs=-1 # 훈련과 예측에 사용할 CPU 코어 수 (-1 : 가용한 모든 코어 사용)\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "bag_model.fit(x_train,y_train)\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = bag_model.predict(x_test)\n",
    "\n",
    "# 모델 평가\n",
    "print(bag_model.__class__.__name__,\" : \",accuracy_score(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T21:43:23.393602Z",
     "end_time": "2023-10-03T21:43:23.573106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\lifelog\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob_score :  0.9516129032258065\n",
      "test_score :  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "# 모델 구축\n",
    "bag_model = BaggingClassifier(\n",
    "    base_estimator = DecisionTreeClassifier(),\n",
    "    n_estimators = 500,\n",
    "    bootstrap = True,\n",
    "    n_jobs = -1,\n",
    "    oob_score = True # oob평가를 위해 True를 지정한다.\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "bag_model.fit(x_train,y_train)\n",
    "\n",
    "# 모델 평가(oob_score_)\n",
    "print('oob_score : ',bag_model.oob_score_)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = bag_model.predict(x_test)\n",
    "print('test_score : ',accuracy_score(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T21:43:24.734634Z",
     "end_time": "2023-10-03T21:43:25.070069Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnd_model :  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 랜덤포레스트 모델 구축\n",
    "rnd_model = RandomForestClassifier(\n",
    "    n_estimators = 500, # 예측기 500개\n",
    "    max_leaf_nodes = 16, # 자식노드의 최대 개수\n",
    "    n_jobs = -1 # CPU 코어 구동 개수\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "rnd_model.fit(x_train,y_train)\n",
    "\n",
    "# 모델 예측\n",
    "y_pred_rf = rnd_model.predict(x_test)\n",
    "\n",
    "# 모델 평가\n",
    "print(\"rnd_model : \",accuracy_score(y_pred_rf,y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T21:43:26.181670Z",
     "end_time": "2023-10-03T21:43:27.010133Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
